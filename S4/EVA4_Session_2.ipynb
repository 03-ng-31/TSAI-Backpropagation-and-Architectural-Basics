{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4 - Session 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZE7DsGzP9jT"
      },
      "source": [
        "# Objectives of the Assignment \n",
        "\n",
        "1. 99.4% validation accuracy\n",
        "2. Less than 20k Parameters\n",
        "3. You can use anything from above you want. \n",
        "4. Less than 20 Epochs\n",
        "5. Have used BN, Dropout, a Fully connected layer, have used GAP. \n",
        "6. To learn how to add different things we covered in this session, \n",
        "\n",
        "you can refer to this code: https://www.kaggle.com/enwei26/mnist-digits-pytorch-cnn-99 DONT COPY ARCHITECTURE, JUST LEARN HOW TO INTEGRATE THINGS LIKE DROPOUT, BATCHNORM, ET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e2NDlzJBX-s"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsaHcj9bmMWZ"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1 , 12, 5) # Input : 1x28x28 , Output : 12x24x24 , RF: 5 , Convolution Operation \n",
        "    self.batch1 = nn.BatchNorm2d(12) # Batch Normalization \n",
        "    self.pool1 = nn.MaxPool2d(2,2) # Input : 12x24x24 , Output : 12x12x12 , RF: 9\n",
        "    self.dropout1 = nn.Dropout(0.25) # Adding Dropouts\n",
        "   \n",
        "    self.conv2 = nn.Conv2d(12, 24, 3) # Input : 12x12x12 , Output : 24x10x10 , RF: 11 ,  Convolution Operation \n",
        "    self.batch2 = nn.BatchNorm2d(24) # Batch Normalization \n",
        "    self.pool2 = nn.MaxPool2d(2,2) # Input : 24x10x10 , Output : 24x5x5 , RF: 13 \n",
        "    self.dropout2 = nn.Dropout(0.25) # Adding Dropouts \n",
        "    \n",
        "    self.conv3 = nn.Conv2d(24, 30, 3) # Input : 24x5x5 , Output : 30x3x3, RF: 15 ,  Convolution Operation \n",
        "    self.batch3 = nn.BatchNorm2d(30) # Batch Normalization \n",
        "    \n",
        "    self.conv4 = nn.Conv2d(30, 10, 3) # Input : 30x3x3 , Output : 10x1x1 , RF : 17 ,  Convolution Operation \n",
        "  \n",
        "  def forward(self, x):\n",
        "    ## Block 1 \n",
        "    x = self.pool1(self.batch1(F.relu(self.conv1(x))))\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    ## Block 2\n",
        "    x = self.pool2(self.batch2(F.relu(self.conv2(x))))\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "    ## Block 3\n",
        "    x = self.batch3(F.relu(self.conv3(x)))\n",
        "    \n",
        "    ## Block 4\n",
        "    x = self.conv4(x)\n",
        "\n",
        "    x = x.view(-1, 10)\n",
        "    return F.log_softmax(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBP6ZKgwpiww"
      },
      "source": [
        "## Intialising the GPU for creating the Convolutional Neural Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbb3390-7773-4725-a018-207f58b347b6"
      },
      "source": [
        "\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 24, 24]             312\n",
            "       BatchNorm2d-2           [-1, 12, 24, 24]              24\n",
            "         MaxPool2d-3           [-1, 12, 12, 12]               0\n",
            "           Dropout-4           [-1, 12, 12, 12]               0\n",
            "            Conv2d-5           [-1, 24, 10, 10]           2,616\n",
            "       BatchNorm2d-6           [-1, 24, 10, 10]              48\n",
            "         MaxPool2d-7             [-1, 24, 5, 5]               0\n",
            "           Dropout-8             [-1, 24, 5, 5]               0\n",
            "            Conv2d-9             [-1, 30, 3, 3]           6,510\n",
            "      BatchNorm2d-10             [-1, 30, 3, 3]              60\n",
            "           Conv2d-11             [-1, 10, 1, 1]           2,710\n",
            "================================================================\n",
            "Total params: 12,280\n",
            "Trainable params: 12,280\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.18\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.23\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f665tYVkBnXk"
      },
      "source": [
        "## Created data that has to be loaded in Bactches "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHhExvbSh8m8",
        "outputId": "8fb51e1c-b315-4a3d-ecb9-11c93d0281d1"
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttl2kMgzBxeJ"
      },
      "source": [
        "## Creating a Training Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGswA_y9B22o"
      },
      "source": [
        "### Model Performance and Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqNf2X8CRju6",
        "outputId": "9dad89df-e768-4f83-88bc-4b096835fe3d"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 20):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.08374646306037903 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0546, Accuracy: 9833/10000 (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08233388513326645 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0386, Accuracy: 9873/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.09380369633436203 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0314, Accuracy: 9894/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08999092131853104 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 10.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0278, Accuracy: 9910/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.02870047651231289 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0246, Accuracy: 9923/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.011713795363903046 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0232, Accuracy: 9922/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.03407595679163933 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0216, Accuracy: 9926/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.06326459348201752 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0221, Accuracy: 9927/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.00679137883707881 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 10.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0220, Accuracy: 9924/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.05831174924969673 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0203, Accuracy: 9934/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.021541709080338478 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0227, Accuracy: 9925/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.04618341848254204 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0213, Accuracy: 9924/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.003008392406627536 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0203, Accuracy: 9932/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.024426346644759178 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 10.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0227, Accuracy: 9929/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.03966282308101654 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0191, Accuracy: 9936/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.034264352172613144 batch_id=468: 100%|██████████| 469/469 [00:41<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0200, Accuracy: 9938/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0020914676133543253 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0187, Accuracy: 9937/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.055500756949186325 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 9939/10000 (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.007333959918469191 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0186, Accuracy: 9942/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbOv7vMmSL2K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}